public:: true
category:: math
sub-category:: analysis
type:: blog
date:: [[Oct 19th, 2023]]

- ## 4 Feasibility of Learning
- ![这里写图片描述](https://wizardforcel.gitbooks.io/ntu-hsuantienlin-ml/content/img/422a4a4e35abaca291d0594bbc78966a.jpg){:height 358, :width 566}
- 如果有一个装有很多（数量很大数不过来）橙色球和绿色球的罐子，我们能不能推断橙色球的比例$u$？统计学上的做法是，从罐子中随机取出$N$个球，作为样本，计算这$N$个球中橙色球的比例$v$，那么就估计出罐子中橙色球的比例约为$v$。
- $Hoeffding不等式$ 说明当$N$很大的时候，$v$与$u$相差不会很大，它们之间的差值被限定在之内。我们把结论$v=u$称为probably approximately correct($PAC$)。
- 这里描述了如何使用统计来连接机器学习，如果我们从算法中获取的 $h(x)$ 在训练数据中的错误率和样本空间的错误率是$PAC$的，即如果我们能保证在训练数据中的错误率小，那么在样本空间的数据也会很小。
- ## Training vs Testing
- ^^训练样本$D$和最终测试$h$的样本都是来自同一个数据分布，这是机器能够学习的前提。^^
- dichotomy就是将空间中的点（例如二维平面）用一条直线分成正类（蓝色o）和负类（红色x）。
- 成长函数（growth function），记为$m_H$。成长函数的定义是：对于由$N$个点组成的不同集合中，某集合对应的dichotomy最大，那么这个dichotomy值就是$m_H$，它的上界是$2^N$
- ## Theory of Generalization
- shatter的意思是对N个点，能够分解为$2^N$种dichotomies
- 当数据的维度(就是那个高高的向量)确定下，在$N>k$时，break point限制了$m_H(N)$值的大小，也就是说影响成长函数$m_H(N)$的因素主要有两个：
	- 抽样数据集 N
	- break point k (这个变量确定了假设的类型)
- 推广一下，也就是说，如果能找到一个模型的break point，且是有限大的，那么就能推断出其成长函数$m_H(N)$有界。最终证明了只要break point存在，那么机器学习就是可行的。
- ## The VC Dimension
- 我们知道如果一个假设空间H有break point k，那么它的成长函数是有界的，它的上界称为Bound function。
	- 空间的breank point k 说明空间中H的数量是有限，即算法选择的g是有限的
- ***注明：*** 文章中所有的图片均来自台湾大学林轩田《机器学习基石》课程。
- ![这里写图片描述](https://wizardforcel.gitbooks.io/ntu-hsuantienlin-ml/content/img/1a241a5e97470e36b6e837ca1c6b7c8f.jpg)
- 这样，不等式只与k和N相关了，一般情况下样本N足够大，所以我们只考虑k值。有如下结论：
	- 若假设空间H有break point k，且N足够大，则根据VC bound理论，算法有良好的泛化能力
	- 在假设空间中选择一个矩g，使 $E_{in} = 0$ ，则其在全集数据中的错误率会较低
-